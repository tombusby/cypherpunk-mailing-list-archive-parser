From: eli+@GS160.SP.CS.CMU.EDU
Date: Fri, 12 Apr 1996 22:22:32 +0800
To: cypherpunks@toad.com
Subject: Re: why compression doesn't perfectly even out entropy
In-Reply-To: <+cmu.andrew.internet.cypherpunks+4lOmu2e00UfA41010Z@andrew.cmu.edu>
Message-ID: <199604111718.KAA29564@cygnus.com>
MIME-Version: 1.0
Content-Type: text/plain


JonWienke@aol.com writes:
>I have no disagreements with this.  I merely proposed using the compression
>function as a means of roughly estimating entropy and preventing the seeding
>of the hash/PRNG with potentially "weak key" type data.

It's not a useful estimate of entropy, and I don't see what you mean
by "`weak key' type data".  There are no keys or PRNGs involved here,
just a hash function.  Now, if you've got a sufficiently compressible
data stream, compression may be a fast way to jump-start the
distillation, but you absolutely need a priori information on the
entropy of the source.

>Would anyone like to propose a means of measuring entropy that we can all
>agree on?

If your definition of entropy is at least as strong as Kolmogorov
complexity, it's infeasible to compute.  The way to measure entropy is
to spend ten years trying to understand the data source, and hope that
no one else can afford to spend twenty.

--
   Eli Brandt
   eli+@cs.cmu.edu





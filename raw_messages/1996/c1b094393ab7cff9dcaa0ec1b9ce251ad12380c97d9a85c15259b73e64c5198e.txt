From: Alan Olsen <alano@teleport.com>
Date: Sat, 13 Apr 1996 18:07:54 +0800
To: Doug Hughes <cypherpunks@toad.com
Subject: Re: questions about bits and bytes
Message-ID: <2.2.32.19960412215132.0095ccdc@mail.teleport.com>
MIME-Version: 1.0
Content-Type: text/plain


At 11:34 AM 4/12/96 -0500, Doug Hughes wrote:
>
>On Apr 12 at 8:07
>jim bell wrote:
>>
>>Are you sure they're not referring to 8 bits of data and a parity bit?  In 
>>any case, please give the address to the list so that it can be checked out.
>
>Come on, give it up already and admit you were wrong. At least 8 different
>people have cited examples of machines that supported non 8bit bytes. Your
>pride is getting the best of you.

Jim is unwilling to admit his errors, even in things he has little or no
training in.  (I remember him claiming at one point that he was not a
programmer or did any coding for that matter.  Why he continues to persist
in such things I will not speculate on...)

I have worked on a couple of machines (that are still in use today) that
were non-standard bit sizes.  Many of the legacy machines from the old
mainframe days (about 20+ years ago) had non-standard bit sizes.  (Which
made communication between then an interesting mess.)  The old Microdata
PICK machines had a weird byte size, for example.  Some of the old Vax
machines had the same "difficulty".

>If you mean 8 bits, you should really say Octets as has always been the
>form of Internet RFC's where the distinction is important.

Making the assumption as to the stability of the sizes of bytes, words, and
characters can get you into alot of trouble in the coding world.

Characters are a good case in point.  Depending on your OS and/or language,
you could be talking about 5, 7, 8 or more bits.  With the need to
distribute applications internationally, the need to support all sorts of
character schemes makes it even more variable.  Unicode is 16 bytes per
character.  Shift JIS can be variable.  (Either 8 or 16, if I remember
correctly.)  It just depends on the hardware, software, and compiler being
used.  I am sure that alot of old code is getting broken by the assumption
that a character is always 8 bits.  Assuming the same about bytes on old
machines will do about as much good.

>It may be standard today, but it was not always so..

And the standards change.  I expect that at some point, some standards group
will change all the terms again.  (And this argument will flare up again...)

---
Alan Olsen -- alano@teleport.com -- Contract Web Design & Instruction
        `finger -l alano@teleport.com` for PGP 2.6.2 key 
                http://www.teleport.com/~alano/ 
  "We had to destroy the Internet in order to save it." - Sen. Exon






